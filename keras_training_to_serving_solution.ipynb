{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving a Keras Resnet Model\n",
    "\n",
    "The Keras exercises are simplified as most of the concepts here are primarily taught in the [Tensorflow Estimator API notebook](./estimator_training_to_serving.ipynb)\n",
    "\n",
    "This notebook teaches how to create a servable Resnet50 model from Keras using a pre-trained Resnet50 ImageNet model provided by the Keras library. The primary objective in this exercise is to convert the model's default input and output formats into one intended , and set its inputs field and output fields in the prediction signature definition in the Tensorflow saved_model library. (Compare this to the Estimator API, where the input signature is defined by the `serving_input_receiver_fn()` dictionary argument, and the output signature is defined by the EstimatorSpec constructor's export_outputs field in the model_fn.\n",
    "\n",
    "See https://github.com/keras-team/keras/blob/master/keras/applications/resnet50.py for the implementation of ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "\n",
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras libraries\n",
    "import keras.applications.resnet50 as resnet50\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "# Import Tensorflow saved model libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def\n",
    "from tensorflow.contrib.session_bundle import exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DEFAULT_IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Output Directory\n",
    "\n",
    "Unlike the Estimator API that automatically creates a servable version number using the unix timestamp, building a servable model directly from a tensorflow graph requires creating an explicit integer version number.\n",
    "\n",
    "Note that if you've successfully saved the servable in a directory, trying to save another servable will fail hard. You always want to increment your version number, or otherwise delete the output directory and re-run the servable creation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_NUMBER = 1\n",
    "SERVING_DIR = \"keras_resnet_servable/\" + str(VERSION_NUMBER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Servable Model from Keras\n",
    "\n",
    "Keras has a prepackaged ImageNet-trained ResNet50 model which takes in a 4d input tensor and outputs a list of class probabilities for all of the classes.\n",
    "\n",
    "We will create a servable model whose input and output formats are identical to that provided in the [Estimator API version](./estimator_training_to_serving_solution.ipynb). Basically, the input needs is a list of jpegs, and the output needs to contain the top k classes and probabilities. We've refactored the input preprocessing and output postprocessing into helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "The point of creating helper functions is two-fold:\n",
    "\n",
    "1. Modularity: you can reuse functions in different places; for instance, a different image model or ResNet architecture can reuse functions.\n",
    "2. Testability: you can unit test different parts of your code easily!\n",
    "\n",
    "We are going to focus on building simple helper functions and performing unit tests below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function: convert JPEG strings to Normalized 3D Tensors\n",
    "\n",
    "The client (resnet_client.py) sends jpeg encoded images into an array of jpegs (each entry a string) to send to the server. These jpegs are all appropriately resized to 224x224x3, and do not need resizing on the server side to enter into the ResNet model. However, the ResNet50 model was trained with pixel values normalized (approximately) between -0.5 and 0.5. We will need to extract the raw 3D tensor from each jpeg string and normalize the values.\n",
    "\n",
    "**Exercise:** Add a command in the helper function to decode the jpeg string into a 3D RGB image tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing helper function similar to `resnet_training_to_serving_solution.ipynb`.\n",
    "\n",
    "def convert_jpeg_to_image(encoded_image):\n",
    "  \"\"\"Preprocesses the image by subtracting out the mean from all channels.\n",
    "  Args:\n",
    "    image: A jpeg-formatted byte stream represented as a string.\n",
    "  Returns:\n",
    "    A 3d tensor of image pixels normalized for the Keras ResNet50 model.\n",
    "      The canned ResNet50 pretrained model was trained after running\n",
    "      keras.applications.resnet50.preprocess_input in 'caffe' mode, which\n",
    "      flips the RGB channels and centers the pixel around the mean [103.939, 116.779, 123.68].\n",
    "      There is no normalizing on the range.\n",
    "  \"\"\"\n",
    "  image = tf.image.decode_jpeg(encoded_image, channels=3)\n",
    "  image = tf.to_float(image)\n",
    "  image = resnet50.preprocess_input(image)  \n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test the helper function\n",
    "\n",
    "Unit testing is discussed in more detail in [the Estimator exercise](./estimator_training_to_serving.ipynb) and will be omitted here.\n",
    "\n",
    "**Exercise:** Construct a tensorflow unit test graph for the preprocessing function.\n",
    "\n",
    "**Hint:** See the [Estimator notebook](./estimator_training_to_serving.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input test graph nodes: only needs to be run once!\n",
    "test_jpeg = tf.placeholder(dtype=tf.string, shape=[], name='test_jpeg')  # A placeholder for a single string, which is a dimensionless (0D) tensor.\n",
    "test_decoded_tensor = convert_jpeg_to_image(test_jpeg)  # Output node, which returns a 3D tensor after processing.\n",
    "\n",
    "# Print the graph elements to check shapes. ? indicates that Tensorflow does not know the length of those dimensions.\n",
    "print(test_jpeg)\n",
    "print(test_decoded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the result of the function using a sample image client/cat_sample.jpg\n",
    "ERROR_TOLERANCE = 1e-4\n",
    "\n",
    "with open(\"client/cat_sample.jpg\", \"rb\") as imageFile:\n",
    "    jpeg_str = imageFile.read()\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(test_decoded_tensor, feed_dict={test_jpeg: jpeg_str})\n",
    "        assert result.shape == (224, 224, 3)\n",
    "        # TODO: Replace with assert statements to check max and min normalized pixel values\n",
    "        assert result.max() <= 255.0 - 103.939 + ERROR_TOLERANCE # Max pixel value after subtracting mean\n",
    "        assert result.min() >= -123.68 - ERROR_TOLERANCE # Min pixel value after subtracting mean\n",
    "        print('Hooray! JPEG decoding test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function: Preprocessing Server Input\n",
    "\n",
    "The server receives a client request in the form of a dictionary {'images': tensor_of_jpeg_encoded_strings}, which must be preprocessed into a 4D tensor before feeding into the Keras ResNet50 model.\n",
    "\n",
    "**Exercise**: You will need to modify the input to the Keras Model to be compliant with [the ResNet client](./client/resnet_client.py). Using tf.map_fn and convert_jpeg_to_image, fill in the missing line (marked ???) to convert the client request into an array of 3D floating-point, preprocessed tensor. The following lines stack and reshape this array into a 4D tensor.\n",
    "\n",
    "**Useful References:**\n",
    "* [tf.map_fn](https://www.tensorflow.org/api_docs/python/tf/map_fn)\n",
    "* [tf.DType](https://www.tensorflow.org/api_docs/python/tf/DType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(jpeg_tensor):\n",
    "    processed_images = tf.map_fn(convert_jpeg_to_image, jpeg_tensor, dtype=tf.float32)  # Convert list of JPEGs to a list of tensors\n",
    "    processed_images = tf.stack(processed_images)  # Convert list of tensors to tensor of tensors\n",
    "    processed_images = tf.reshape(tensor=processed_images,  # Reshape to ensure TF graph knows the final dimensions\n",
    "                                shape=[-1, _DEFAULT_IMAGE_SIZE, _DEFAULT_IMAGE_SIZE, 3])\n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test the Input Preprocessing Helper Function\n",
    "\n",
    "**Exercise**: Construct a tensorflow unit test graph for the input function.\n",
    "\n",
    "**Hint:** the input node test_jpeg_tensor should be a [tf.placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder). You need to define the `shape` parameter in tf.placeholder. `None` inside an array indicates that the length can vary along that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Test Input Preprocessing Network: only needs to be run once!\n",
    "test_jpeg_tensor = tf.placeholder(dtype=tf.string, shape=[None], name='test_jpeg_tensor')  # A placeholder for a single string, which is a dimensionless (0D) tensor.\n",
    "test_processed_images = preprocess_input(test_jpeg_tensor)  # Output node, which returns a 3D tensor after processing.\n",
    "\n",
    "# Print the graph elements to check shapes. ? indicates that Tensorflow does not know the length of those dimensions.\n",
    "print(test_jpeg_tensor)\n",
    "print(test_processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test network using a sample image client/cat_sample.jpg\n",
    "\n",
    "with open(\"client/cat_sample.jpg\", \"rb\") as imageFile:\n",
    "    jpeg_str = imageFile.read()\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(test_processed_images, feed_dict={test_jpeg_tensor: np.array([jpeg_str, jpeg_str])})  # Duplicate for length 2 array\n",
    "        assert result.shape == (2, 224, 224, 3)  # 4D tensor with first dimension length 2, since we have 2 images\n",
    "        # TODO: add a test for min and max normalized pixel values\n",
    "        assert result.max() <= 255.0 - 103.939 + ERROR_TOLERANCE  # Normalized\n",
    "        assert result.min() >= -123.68 - ERROR_TOLERANCE  # Normalized\n",
    "        # TODO: add a test to verify that the resulting tensor for image 0 and image 1 are identical.\n",
    "        assert result[0].all() == result[1].all()\n",
    "        print('Hooray! Input unit test succeeded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function: Postprocess Server Output\n",
    "\n",
    "**Exercise:** The Keras model returns a 1D tensor of probabilities for each class. We want to wrote a postprocess_output() that returns only the top k classes and probabilities.\n",
    "\n",
    "**Useful References:**\n",
    "* [tf.nn.top_k](https://www.tensorflow.org/api_docs/python/tf/nn/top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "\n",
    "def postprocess_output(model_output):\n",
    "    '''Return top k classes and probabilities.'''\n",
    "    top_k_probs, top_k_classes = tf.nn.top_k(model_output, k=TOP_K)\n",
    "    return {'classes': top_k_classes, 'probabilities': top_k_probs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test the Output Postprocessing Helper Function\n",
    "\n",
    "**Exercise:** Fill in the shape field for the model output, which should be a tensor of probabilities.\n",
    "\n",
    "**Hint:** how many image classes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Test Output Postprocessing Network: only needs to be run once!\n",
    "test_model_output = tf.placeholder(dtype=tf.float32, shape=[1001], name='test_logits_tensor')\n",
    "test_prediction_output = postprocess_output(test_model_output)\n",
    "\n",
    "# Print the graph elements to check shapes.\n",
    "print(test_model_output)\n",
    "print(test_prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy testing framework for float comparisons\n",
    "import numpy.testing as npt\n",
    "\n",
    "# Run test network\n",
    "# Input a tensor with clear winners, and perform checks\n",
    "\n",
    "model_probs = np.ones(1001)\n",
    "model_probs[2] = 2.5\n",
    "model_probs[5] = 3.5\n",
    "model_probs[10] = 4\n",
    "model_probs[49] = 3\n",
    "model_probs[998] = 2\n",
    "TOTAL_WEIGHT = np.sum(model_probs)\n",
    "model_probs = model_probs / TOTAL_WEIGHT\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(test_prediction_output, {test_model_output: model_probs})\n",
    "    classes = result['classes']\n",
    "    probs = result['probabilities']\n",
    "    # Check values\n",
    "    assert len(probs) == 5\n",
    "    npt.assert_almost_equal(probs[0], model_probs[10])\n",
    "    npt.assert_almost_equal(probs[1], model_probs[5])\n",
    "    npt.assert_almost_equal(probs[2], model_probs[49])\n",
    "    npt.assert_almost_equal(probs[3], model_probs[2])\n",
    "    npt.assert_almost_equal(probs[4], model_probs[998])\n",
    "    assert len(classes) == 5\n",
    "    assert classes[0] == 10\n",
    "    assert classes[1] == 5\n",
    "    assert classes[2] == 49\n",
    "    assert classes[3] == 2\n",
    "    assert classes[4] == 998\n",
    "    print('Hooray! Output unit test succeeded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Keras Model and Build the Graph\n",
    "\n",
    "The Keras Model uses Tensorflow as its backend, and therefore its inputs and outputs can be treated as elements of a Tensorflow graph. In other words, you can provide an input that is a Tensorflow tensor, and read the model output like a Tensorflow tensor!\n",
    "\n",
    "**Exercise**: Build the end to end network by filling in the TODOs below.\n",
    "\n",
    "**Useful References**:\n",
    "* [Keras ResNet50 API](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)\n",
    "* [Keras Model class API](https://faroit.github.io/keras-docs/1.2.2/models/model/): ResNet50 model inherits this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a placeholder for your arbitrary-length 1D Tensor of JPEG strings\n",
    "images = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "\n",
    "# TODO: Call preprocess_input to return processed_images\n",
    "processed_images = preprocess_input(images)\n",
    "\n",
    "# Load (and download if missing) the ResNet50 Keras Model (may take a while to run)\n",
    "# TODO: Use processed_images as input\n",
    "model = resnet50.ResNet50(input_tensor=processed_images)\n",
    "# Rename the model to 'resnet' for serving\n",
    "model.name = 'resnet'\n",
    "\n",
    "# TODO: Call postprocess_output on the output of the model to create predictions to send back to the client\n",
    "predictions = postprocess_output(model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Input-Output Signature\n",
    "\n",
    "**Exercise:** The final step to creating a servable model is to define the end-to-end input and output API. Edit the inputs and outputs parameters to predict_signature_def below to ensure that the signature correctly handles client request. The inputs parameter should be a dictionary {'images': tensor_of_strings}, and the outputs parameter a dictionary {'classes': tensor_of_top_k_classes, 'probabilities': tensor_of_top_k_probs}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a saved model builder as an endpoint to dataflow execution\n",
    "builder = saved_model_builder.SavedModelBuilder(SERVING_DIR)\n",
    "\n",
    "# TODO: set the inputs and outputs parameters in predict_signature_def()\n",
    "signature = predict_signature_def(inputs={'images': images},\n",
    "                                  outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Servable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.get_session() as sess:\n",
    "    builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                         tags=[tag_constants.SERVING],\n",
    "                                         signature_def_map={'predict': signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
