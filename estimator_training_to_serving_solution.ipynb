{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving a Resnet TF Estimator Model\n",
    "\n",
    "**Scenario:** In Tensorflow 1.3, a higher level API called Estimators was introduced and has since been a popular API of choice within the Tensorflow community. Suppose that an ML researcher has trained a Resnet model on the Imagenet dataset using Tensorflow's Estimator API, located at https://github.com/tensorflow/models/tree/v1.4.0/official/resnet. (Note that we used v1.4.0. You always want to use a stable tag for a model version to deploy as the researcher can continue to modify the model and architecture at the head of master.) Our task is to deploy this model into Tensorflow Serving. You have access to their python code as well as a saved state (checkpoint) that points to their favorite trained result.\n",
    "\n",
    "The first step is to create a servable version of the model that will be used for Tensorflow Serving, which runs very efficiently in C++, and is platform independent (can run on different OSes, as well as hardware with different types of accelerators such as GPUs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "\n",
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download model checkpoint\n",
    "\n",
    "The next step is to load the researcher's saved checkpoint into our estimator. We will download it from\n",
    "http://download.tensorflow.org/models/official/resnet50_2017_11_30.tar.gz using the commands below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a constant indicating the number of layers in our loaded model. We're loading a resnet-50 model.\n",
    "RESNET_SIZE = 50  \n",
    "\n",
    "# Model and serving directories\n",
    "MODEL_DIR=\"resnet_model_checkpoints\"\n",
    "SERVING_DIR=\"resnet_servable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"http://download.tensorflow.org/models/official/resnet50_2017_11_30.tar.gz \", \"resnet.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip the file into a directory called resnet\n",
    "from subprocess import call\n",
    "call([\"mkdir\", MODEL_DIR])\n",
    "call([\"tar\", \"-zxvf\", \"resnet.tar.gz\", \"-C\", MODEL_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you see model checkpoint files in this directory\n",
    "os.listdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Model Architecture\n",
    " \n",
    "In order to reconstruct the Resnet neural network used to train the Imagenet model, we need to load the architecture pieces. During the setup step, we checked out https://github.com/tensorflow/models/tree/v1.4.0/official/resnet. We can now load functions and constants from resnet_model.py into the notebook.\n",
    "\n",
    "**Exercise:** We also need some constants from [imagenet_main.py](https://github.com/tensorflow/models/blob/v1.4.0/official/resnet/imagenet_main.py), but we cannot run this file as it is a main class that trains ResNet. Open [imagenet_main.py](https://github.com/tensorflow/models/blob/v1.4.0/official/resnet/imagenet_main.py) and copy over a few constants that are important, such as the image size, channels, and number of classes, in the cell below with the TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../models/official/resnet/resnet_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy constants from imagenet_main.py.\n",
    "#\n",
    "# Hint: You do not need to copy all constants, such as those pertaining only to training and validation.\n",
    "# What constants are useful for prediction?\n",
    "#\n",
    "# Hint 2: What constants are referenced in the code cells below for prediction? You may come back to edit this cell.\n",
    "\n",
    "_DEFAULT_IMAGE_SIZE = 224\n",
    "_NUM_CHANNELS = 3\n",
    "_LABEL_CLASSES = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess JPEG images into 3D Tensors\n",
    "\n",
    "In order to reduce network overhead, we've provided a client (resnet_client.py) that will encode images into an array of jpegs (encoded as byte strings) to send to the server. These jpegs are all appropriately resized to 224x224x3, and do not need resizing on the server side to enter into the ResNet model.\n",
    "\n",
    "**Exercise:** Create a helper function that decodes a jpeg image, and normalizes pixel values to be between -0.5 and 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(encoded_image, height=_DEFAULT_IMAGE_SIZE, width=_DEFAULT_IMAGE_SIZE):\n",
    "  \"\"\"Preprocesses the image by subtracting out the mean from all channels.\n",
    "  Args:\n",
    "    image: A jpeg-formatted byte stream represented as a string.\n",
    "  Returns:\n",
    "    A 3d tensor of image pixels normalized to be between -0.5 and 0.5, resized to height x width x 3.\n",
    "    The normalization is an approximation of the preprocess_for_train and preprocess_for_eval functions in\n",
    "    https://github.com/tensorflow/models/blob/v1.4.0/official/resnet/vgg_preprocessing.py.\n",
    "  \"\"\"\n",
    "  image = tf.image.decode_jpeg(encoded_image, channels=3)  # TODO: Use a tf function to decode the jpeg into a 3d tensor.\n",
    "  image = tf.to_float(image) / 255.0 - 0.5  # Normalize values to be between -0.5 and 0.5.\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Servable from the Estimator API\n",
    "\n",
    "Within the Tensorflow Estimator API, a model function defines graph elements used in training, evaluation, and prediction. Depending on the mode (TRAIN, EVAL, PREDICT) used, the model function will return an [EstimatorSpec](https://www.tensorflow.org/versions/r1.3/extend/estimators#constructing_the_model_fn) object tell the Estimator to run different graph elements. For instance:\n",
    "\n",
    "* TRAIN mode would usually involve calling an optimizer that is hooked to a loss function (e.g. cross-entropy), which depends on the logits for each class, which depends on lower layers of the network, etc.\n",
    "* EVAL mode would not call the optimizer, but would call the loss function and/or some other evaluation metric (e.g. accuracy). These evaluation metrics will likely depend on labels as well as the logits of the network output, which depends on lower layers of the network, etc.\n",
    "  * Additionally, researchers will often use monitors and hooks during training and evaluation to check on the progress of the model. Usually, these components are used to return summaries about different layers of the network, such as model coefficients, etc., which can be visualized using [Tensorboard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard).\n",
    "* PREDICT mode does NOT require an optimizer as there is no training step. Also, input data is unlabeled, so no loss functions or evaluation metrics are used. Instead, predictions simply try to provide clients/users with information of interest, such as the most likely label for an image, the probability of the image being of a particular class, etc.\n",
    "\n",
    "**Exercise:** The model server is primarily used to PREDICT. Therefore, many graph elements in the training code located in the imagenet_main.py [resnet_model_fn()](https://github.com/tensorflow/models/blob/v1.4.0/official/resnet/imagenet_main.py#L162) are no longer relevant. We are going to modify the function in several ways:\n",
    "\n",
    "1. Remove/shortcut many graph elements unrelate to prediction.\n",
    "\n",
    "2. Change the way input features are read to be compliant with our [client](https://github.com/google-aai/tf-serving-k8s-tutorial/blob/master/client/resnet_client.py). In particular, training data is prepackaged as a [TF Dataset](https://www.tensorflow.org/programmers_guide/datasets) with information such as labels, text, encoding, bounding boxes, etc. Our client's behavior is very simple: we send a message with a single field 'images' containing a batch (array) of jpeg-encoded images as strings.\n",
    "\n",
    "3. Modify the `prediction` value to return the top K likely classes and their probabilities! This may be more useful than returning just the top class and probability, as it helps the user determine whether the model is confused about a particular image's class!\n",
    "\n",
    "**Useful References:**\n",
    "* [tf.map_fn](https://www.tensorflow.org/api_docs/python/tf/map_fn)\n",
    "* [tf.DType](https://www.tensorflow.org/api_docs/python/tf/DType)\n",
    "* [ResNet Model Code](https://github.com/tensorflow/models/blob/v1.4.0/official/resnet/resnet_model.py)\n",
    "* [tf.nn.top_k](https://www.tensorflow.org/api_docs/python/tf/nn/top_k)\n",
    "* [tf.estimator.EstimatorSpec](https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "\n",
    "def resnet_model_fn(features, labels, mode):\n",
    "  \n",
    "  # tf.summary.image removed as it is used only for training and validation.\n",
    "  \n",
    "  # TODO: the features received from our client is simply a dictionary {'images' : tensor_of_jpeg_byte_strings}.\n",
    "  # Use tf.map_fn and the helper function above to preprocess the tensor_of_jpeg_byte_strings into a list of\n",
    "  # single-precision floating point 3D tensors.\n",
    "  images = features['images']  # A tensor of tf.strings\n",
    "  processed_images = tf.map_fn(preprocess_image, images, dtype=tf.float32)\n",
    "  processed_images = tf.stack(processed_images)  # Convert list of 3D tensors to a 4D tensor\n",
    "  processed_images = tf.reshape(tensor=processed_images,  # Reshaping informs Tensorflow of the final dimensions of the 4D tensor\n",
    "                                shape=[-1, _DEFAULT_IMAGE_SIZE, _DEFAULT_IMAGE_SIZE, 3])\n",
    "\n",
    "  # TODO: You are building a servable model that is optimized toward your particular cluster type. \n",
    "  # For CNNs, it has been shown that placing your color channels ('channels_first') before your pixel dimensions \n",
    "  # in the image tensor significantly improves performance over 'channels_last'. \n",
    "  # \n",
    "  # Feel free to try out both data formats, i.e. 'channels_first' and 'channels_last',\n",
    "  # to compare performances during serving.\n",
    "  #\n",
    "  # HOWEVER, validating the servable (i.e. `resnet_servable_validation.ipynb`) REQUIRES 'channels_last'\n",
    "  # due to limitations in the tf.contrib.predict package. If you want to validate your servable,\n",
    "  # we suggest you start by creating a servable with data format 'channels_last' for validation,\n",
    "  # then recreate a servable with 'channels_first' as this should also work without issues.\n",
    "  network = imagenet_resnet_v2(RESNET_SIZE, _LABEL_CLASSES, data_format='channels_last')\n",
    "\n",
    "  # NOTE: No need to change this, but is_training will always be false since we are predicting.\n",
    "  logits = network(\n",
    "      inputs=processed_images, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "  # TODO: Instead of the top 1 result, create a predictions dictionary that contains fields:\n",
    "  # 'classes': 1D-tensor of top k classes\n",
    "  # 'probabilities': 1D-tensor of top k probabilities.\n",
    "  # HINT: Use tf.nn.top_k.\n",
    "  top_k_logits, top_k_classes = tf.nn.top_k(logits, k=TOP_K)\n",
    "  top_k_probs = tf.nn.softmax(top_k_logits)\n",
    "  predictions = {\n",
    "      'classes': top_k_classes,\n",
    "      'probabilities': top_k_probs\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return create_servable_estimator_spec(predictions, mode)\n",
    "\n",
    "  # TODO: Shortcut everything below here by returning a minimal EstimatorSpec.\n",
    "  return tf.estimator.EstimatorSpec(mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Servable Model API Definition\n",
    "\n",
    "The EstimatorSpec contains a field `export_outputs`, which defines the dictionary of fields that the servable model will return to a client upon receiving a request. To export the predictions dictionary above using Tf serving, you will need to assign the export_outputs parameter in EstimatorSpec.\n",
    "\n",
    "**Exercise:** Add a dictionary with a string key which will be the request.model_spec.signature_name that\n",
    "your client will call in `client/resnet_client.py`. (See client/resnet_client.py)\n",
    "Add a value that is tf.estimator.export.PredictOutput(outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_servable_estimator_spec(predictions, mode):\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=predictions,  # Note: This is not be used in serving, but must be provided for the Estimator API.\n",
    "      export_outputs={\n",
    "          'predict': tf.estimator.export.PredictOutput(outputs=predictions)  # TODO: assign an appropriate dictionary to the export_outputs parameter here.\n",
    "      },\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this model into our estimator\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=resnet_model_fn,  # Call our generate_model_fn to create model function\n",
    "  model_dir=MODEL_DIR,  # Where to look for model checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving input receiver function\n",
    "\n",
    "Tensorflow uses [placeholders](https://www.tensorflow.org/api_docs/python/tf/placeholder) as entrypoints for ingesting data into its graphs. For example, if you create a placeholder with dimensions [100, 50], you can pass in a numpy array of dimension (100, 50), and run the graph with the placeholder substituted by a 2d tensor with the numpy array values. However, this requires several steps, such as creating a [Tensorflow Session, passing in a feed dictionary, and running the session](https://www.tensorflow.org/api_docs/python/tf/Session).\n",
    "\n",
    "The same principle applies for Tensorflow serving, except that the placeholder holds values sent to the server from the client. Tensorflow Estimator API simplifies the process above by providing \"serving input receiver functions\" as will be seen in the below exercise.\n",
    "\n",
    "**Exercise**: Recall that your client is sending a message of the format:\n",
    "\n",
    "```\n",
    "{'images': array_of_jpeg_encoded_images_as_strings}\n",
    "```\n",
    "\n",
    "Add the following argument to [build_raw_serving_input_receiver_fn()](https://www.tensorflow.org/api_docs/python/tf/estimator/export/build_parsing_serving_input_receiver_fn) below: a dictionary with a single key 'images', and value [tf.placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) that can read in an arbitrary length array of strings.\n",
    "\n",
    "**Hint:** You need to define the `shape` parameter in tf.placeholder. `None` inside an array indicates that the length can vary along that dimension.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "  return tf.estimator.export.build_raw_serving_input_receiver_fn(\n",
    "      {'images': tf.placeholder(dtype=tf.string, shape=[None])}\n",
    "  )()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to save the servable to disk. If this works, we're done!\n",
    "# Note: most of your setup errors will show up after running this step.\n",
    "estimator.export_savedmodel(export_dir_base=SERVING_DIR,\n",
    "                            serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
