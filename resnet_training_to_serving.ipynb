{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving a Resnet TF Estimator Model\n",
    "\n",
    "**Scenario:** An ML researcher has trained a Resnet model on the Imagenet dataset using Tensorflow's Estimator API, located at https://github.com/tensorflow/models/tree/v1.4.0/official/resnet. (Note that we used v1.4.0. You always want to use a stable tag for a model version to deploy as the researcher can continue to modify the model and architecture at the head of master.) Our task is to deploy this model into Tensorflow Serving. You have access to his python code as well as a saved state (checkpoint) that points to his favorite trained result.\n",
    "\n",
    "The first step is to create a servable version of the model that will be used for Tensorflow Serving, which runs very efficiently in C++, and is platform independent (can run on different OSes, as well as hardware with different types of accelerators such as GPUs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "\n",
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download model checkpoint\n",
    "\n",
    "The next step is to load the researcher's saved checkpoint into our estimator. We will download it from\n",
    "http://download.tensorflow.org/models/official/resnet50_2017_11_30.tar.gz using the commands below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a constant indicating the number of layers in our loaded model. We're loading a resnet-50 model.\n",
    "RESNET_SIZE = 50  \n",
    "\n",
    "# Model and serving directories\n",
    "MODEL_DIR=\"resnet_model_checkpoints\"\n",
    "SERVING_DIR=\"resnet_servable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"http://download.tensorflow.org/models/official/resnet50_2017_11_30.tar.gz \", \"resnet.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip the file into a directory called resnet\n",
    "from subprocess import call\n",
    "call([\"mkdir\", MODEL_DIR])\n",
    "call([\"tar\", \"-zxvf\", \"resnet.tar.gz\", \"-C\", MODEL_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you see model checkpoint files in this directory\n",
    "os.listdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Constants and Functions\n",
    " \n",
    "In order to reconstruct the Resnet neural network used to train the Imagenet model, we need to load the architecture pieces. If you were working in the original repository under the python library structure, you can run imports on your python libraries (e.g. import resnet) to access constants and functions in ttps://github.com/tensorflow/models/blob/v1.4.0/official/resnet/imagenet_main.py and https://github.com/tensorflow/models/blob/v1.4.0/official/resnet/resnet.py. However, since we are building the servable model using a notebook for better step-by-step instruction, we need to copy over the constants and functions used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add constants defining elements of the network here.\n",
    "# Hint 1: See the top of https://github.com/tensorflow/models/blob/master/official/resnet/imagenet_main.py\n",
    "# Hint 2: You do not need to copy all constants, such as those pertaining to training and validation.\n",
    "\n",
    "\n",
    "# TODO: Add parameters for batch normalization\n",
    "# Hint 1: See https://github.com/tensorflow/models/blob/master/official/resnet/resnet.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we have copied the functions from the files.\n",
    "Note that we omitted some functions (cifar-related functions) as these are not relevant to imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_relu(inputs, is_training, data_format):\n",
    "  \"\"\"Performs a batch normalization followed by a ReLU.\"\"\"\n",
    "  # We set fused=True for a significant performance boost. See\n",
    "  # https://www.tensorflow.org/performance/performance_guide#common_fused_ops\n",
    "  inputs = tf.layers.batch_normalization(\n",
    "      inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
    "      momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n",
    "      scale=True, training=is_training, fused=True)\n",
    "  inputs = tf.nn.relu(inputs)\n",
    "  return inputs\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "  \"\"\"Pads the input along the spatial dimensions independently of input size.\n",
    "  Args:\n",
    "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "      [batch, height_in, width_in, channels] depending on data_format.\n",
    "    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
    "                 Should be a positive integer.\n",
    "    data_format: The input format ('channels_last' or 'channels_first').\n",
    "  Returns:\n",
    "    A tensor with the same format as the input with the data either intact\n",
    "    (if kernel_size == 1) or padded (if kernel_size > 1).\n",
    "  \"\"\"\n",
    "  pad_total = kernel_size - 1\n",
    "  pad_beg = pad_total // 2\n",
    "  pad_end = pad_total - pad_beg\n",
    "\n",
    "  if data_format == 'channels_first':\n",
    "    padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
    "                                    [pad_beg, pad_end], [pad_beg, pad_end]])\n",
    "  else:\n",
    "    padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                    [pad_beg, pad_end], [0, 0]])\n",
    "  return padded_inputs\n",
    "\n",
    "\n",
    "def conv2d_fixed_padding(inputs, filters, kernel_size, strides, data_format):\n",
    "  \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n",
    "  # The padding is consistent and is based only on `kernel_size`, not on the\n",
    "  # dimensions of `inputs` (as opposed to using `tf.layers.conv2d` alone).\n",
    "  if strides > 1:\n",
    "    inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "\n",
    "  return tf.layers.conv2d(\n",
    "      inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "      padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,\n",
    "      kernel_initializer=tf.variance_scaling_initializer(),\n",
    "      data_format=data_format)\n",
    "\n",
    "\n",
    "def building_block(inputs, filters, is_training, projection_shortcut, strides,\n",
    "                   data_format):\n",
    "  \"\"\"Standard building block for residual networks with BN before convolutions.\n",
    "  Args:\n",
    "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "      [batch, height_in, width_in, channels] depending on data_format.\n",
    "    filters: The number of filters for the convolutions.\n",
    "    is_training: A Boolean for whether the model is in training or inference\n",
    "      mode. Needed for batch normalization.\n",
    "    projection_shortcut: The function to use for projection shortcuts (typically\n",
    "      a 1x1 convolution when downsampling the input).\n",
    "    strides: The block's stride. If greater than 1, this block will ultimately\n",
    "      downsample the input.\n",
    "    data_format: The input format ('channels_last' or 'channels_first').\n",
    "  Returns:\n",
    "    The output tensor of the block.\n",
    "  \"\"\"\n",
    "  shortcut = inputs\n",
    "  inputs = batch_norm_relu(inputs, is_training, data_format)\n",
    "\n",
    "  # The projection shortcut should come after the first batch norm and ReLU\n",
    "  # since it performs a 1x1 convolution.\n",
    "  if projection_shortcut is not None:\n",
    "    shortcut = projection_shortcut(inputs)\n",
    "\n",
    "  inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
    "      data_format=data_format)\n",
    "\n",
    "  inputs = batch_norm_relu(inputs, is_training, data_format)\n",
    "  inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=3, strides=1,\n",
    "      data_format=data_format)\n",
    "\n",
    "  return inputs + shortcut\n",
    "\n",
    "\n",
    "def bottleneck_block(inputs, filters, is_training, projection_shortcut,\n",
    "                     strides, data_format):\n",
    "  \"\"\"Bottleneck block variant for residual networks with BN before convolutions.\n",
    "  Args:\n",
    "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "      [batch, height_in, width_in, channels] depending on data_format.\n",
    "    filters: The number of filters for the first two convolutions. Note that the\n",
    "      third and final convolution will use 4 times as many filters.\n",
    "    is_training: A Boolean for whether the model is in training or inference\n",
    "      mode. Needed for batch normalization.\n",
    "    projection_shortcut: The function to use for projection shortcuts (typically\n",
    "      a 1x1 convolution when downsampling the input).\n",
    "    strides: The block's stride. If greater than 1, this block will ultimately\n",
    "      downsample the input.\n",
    "    data_format: The input format ('channels_last' or 'channels_first').\n",
    "  Returns:\n",
    "    The output tensor of the block.\n",
    "  \"\"\"\n",
    "  shortcut = inputs\n",
    "  inputs = batch_norm_relu(inputs, is_training, data_format)\n",
    "\n",
    "  # The projection shortcut should come after the first batch norm and ReLU\n",
    "  # since it performs a 1x1 convolution.\n",
    "  if projection_shortcut is not None:\n",
    "    shortcut = projection_shortcut(inputs)\n",
    "\n",
    "  inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=1, strides=1,\n",
    "      data_format=data_format)\n",
    "\n",
    "  inputs = batch_norm_relu(inputs, is_training, data_format)\n",
    "  inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
    "      data_format=data_format)\n",
    "\n",
    "  inputs = batch_norm_relu(inputs, is_training, data_format)\n",
    "  inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,\n",
    "      data_format=data_format)\n",
    "\n",
    "  return inputs + shortcut\n",
    "\n",
    "\n",
    "def block_layer(inputs, filters, block_fn, blocks, strides, is_training, name,\n",
    "                data_format):\n",
    "  \"\"\"Creates one layer of blocks for the ResNet model.\n",
    "  Args:\n",
    "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "      [batch, height_in, width_in, channels] depending on data_format.\n",
    "    filters: The number of filters for the first convolution of the layer.\n",
    "    block_fn: The block to use within the model, either `building_block` or\n",
    "      `bottleneck_block`.\n",
    "    blocks: The number of blocks contained in the layer.\n",
    "    strides: The stride to use for the first convolution of the layer. If\n",
    "      greater than 1, this layer will ultimately downsample the input.\n",
    "    is_training: Either True or False, whether we are currently training the\n",
    "      model. Needed for batch norm.\n",
    "    name: A string name for the tensor output of the block layer.\n",
    "    data_format: The input format ('channels_last' or 'channels_first').\n",
    "  Returns:\n",
    "    The output tensor of the block layer.\n",
    "  \"\"\"\n",
    "  # Bottleneck blocks end with 4x the number of filters as they start with\n",
    "  filters_out = 4 * filters if block_fn is bottleneck_block else filters\n",
    "\n",
    "  def projection_shortcut(inputs):\n",
    "    return conv2d_fixed_padding(\n",
    "        inputs=inputs, filters=filters_out, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "\n",
    "  # Only the first block per block_layer uses projection_shortcut and strides\n",
    "  inputs = block_fn(inputs, filters, is_training, projection_shortcut, strides,\n",
    "                    data_format)\n",
    "\n",
    "  for _ in range(1, blocks):\n",
    "    inputs = block_fn(inputs, filters, is_training, None, 1, data_format)\n",
    "\n",
    "  return tf.identity(inputs, name)\n",
    "\n",
    "\n",
    "def imagenet_resnet_v2_generator(block_fn, layers, num_classes,\n",
    "                                 data_format=None):\n",
    "  \"\"\"Generator for ImageNet ResNet v2 models.\n",
    "  Args:\n",
    "    block_fn: The block to use within the model, either `building_block` or\n",
    "      `bottleneck_block`.\n",
    "    layers: A length-4 array denoting the number of blocks to include in each\n",
    "      layer. Each layer consists of blocks that take inputs of the same size.\n",
    "    num_classes: The number of possible classes for image classification.\n",
    "    data_format: The input format ('channels_last', 'channels_first', or None).\n",
    "      If set to None, the format is dependent on whether a GPU is available.\n",
    "  Returns:\n",
    "    The model function that takes in `inputs` and `is_training` and\n",
    "    returns the output tensor of the ResNet model.\n",
    "  \"\"\"\n",
    "  if data_format is None:\n",
    "    data_format = (\n",
    "        'channels_first' if tf.test.is_built_with_cuda() else 'channels_last')\n",
    "\n",
    "  def model(inputs, is_training):\n",
    "    \"\"\"Constructs the ResNet model given the inputs.\"\"\"\n",
    "    if data_format == 'channels_first':\n",
    "      # Convert the inputs from channels_last (NHWC) to channels_first (NCHW).\n",
    "      # This provides a large performance boost on GPU. See\n",
    "      # https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "      inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs=inputs, filters=64, kernel_size=7, strides=2,\n",
    "        data_format=data_format)\n",
    "    inputs = tf.identity(inputs, 'initial_conv')\n",
    "    inputs = tf.layers.max_pooling2d(\n",
    "        inputs=inputs, pool_size=3, strides=2, padding='SAME',\n",
    "        data_format=data_format)\n",
    "    inputs = tf.identity(inputs, 'initial_max_pool')\n",
    "\n",
    "    inputs = block_layer(\n",
    "        inputs=inputs, filters=64, block_fn=block_fn, blocks=layers[0],\n",
    "        strides=1, is_training=is_training, name='block_layer1',\n",
    "        data_format=data_format)\n",
    "    inputs = block_layer(\n",
    "        inputs=inputs, filters=128, block_fn=block_fn, blocks=layers[1],\n",
    "        strides=2, is_training=is_training, name='block_layer2',\n",
    "        data_format=data_format)\n",
    "    inputs = block_layer(\n",
    "        inputs=inputs, filters=256, block_fn=block_fn, blocks=layers[2],\n",
    "        strides=2, is_training=is_training, name='block_layer3',\n",
    "        data_format=data_format)\n",
    "    inputs = block_layer(\n",
    "        inputs=inputs, filters=512, block_fn=block_fn, blocks=layers[3],\n",
    "        strides=2, is_training=is_training, name='block_layer4',\n",
    "        data_format=data_format)\n",
    "\n",
    "    inputs = batch_norm_relu(inputs, is_training, data_format)\n",
    "    inputs = tf.layers.average_pooling2d(\n",
    "        inputs=inputs, pool_size=7, strides=1, padding='VALID',\n",
    "        data_format=data_format)\n",
    "    inputs = tf.identity(inputs, 'final_avg_pool')\n",
    "    inputs = tf.reshape(inputs,\n",
    "                        [-1, 512 if block_fn is building_block else 2048])\n",
    "    inputs = tf.layers.dense(inputs=inputs, units=num_classes)\n",
    "    inputs = tf.identity(inputs, 'final_dense')\n",
    "    return inputs\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "def imagenet_resnet_v2(resnet_size, num_classes, data_format=None):\n",
    "  \"\"\"Returns the ResNet model for a given size and number of output classes.\"\"\"\n",
    "  model_params = {\n",
    "      18: {'block': building_block, 'layers': [2, 2, 2, 2]},\n",
    "      34: {'block': building_block, 'layers': [3, 4, 6, 3]},\n",
    "      50: {'block': bottleneck_block, 'layers': [3, 4, 6, 3]},\n",
    "      101: {'block': bottleneck_block, 'layers': [3, 4, 23, 3]},\n",
    "      152: {'block': bottleneck_block, 'layers': [3, 8, 36, 3]},\n",
    "      200: {'block': bottleneck_block, 'layers': [3, 24, 36, 3]}\n",
    "  }\n",
    "\n",
    "  if resnet_size not in model_params:\n",
    "    raise ValueError('Not a valid resnet_size:', resnet_size)\n",
    "\n",
    "  params = model_params[resnet_size]\n",
    "  return imagenet_resnet_v2_generator(\n",
    "      params['block'], params['layers'], num_classes, data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing JPEG images into 3D Tensors\n",
    "\n",
    "In order to reduce network usage, the client that we've provided (resnet_client.py) will resize the images appropriately (usually reducing the size) to 224x224x3, and then use jpeg encoding to create a string.\n",
    "\n",
    "In this section, we will implement a function that will read in a tensor of JPEG-encoded images and\n",
    "predict their classes and probabilities. The Resnet model requires a 4d tensor of dimensions (x, 224, 224, 3),\n",
    "where x is variable length, and the others correspond to height, width, and channels. Consequently,\n",
    "we will need a utility function to preprocess each image into a 3d tensor of size (224, 224, 3),\n",
    "and concatenate them together into a 4d tensor.\n",
    "\n",
    "Below is a preprocessing function for converting a jpeg to a properly sized 3d tensor, normalizing pixel values, and padding outer regions with zeros until it is properly sized. Note that the last step is unnecessary given that our client already resizes the images appropriately, but we keep it here for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(encoded_image, height=_DEFAULT_IMAGE_SIZE, width=_DEFAULT_IMAGE_SIZE):\n",
    "  \"\"\"Preprocesses the image by subtracting out the mean from all channels.\n",
    "  Args:\n",
    "    image: A jpeg-formatted byte stream represented as a string.\n",
    "  Returns:\n",
    "    A 3d tensor of image pixels normalized to be between -0.5 and 0.5, resized to height x width x 3.\n",
    "    The normalization is an approximation of the preprocess_for_train and preprocess_for_eval functions in\n",
    "    https://github.com/tensorflow/models/blob/v1.4.0/official/resnet/vgg_preprocessing.py.\n",
    "  \"\"\"\n",
    "  image = tf.image.decode_jpeg(encoded_image, channels=3)\n",
    "  image = tf.to_float(image) / 255.0 - 0.5\n",
    "  image = tf.image.resize_image_with_crop_or_pad(image, height, width)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet Model Function\n",
    "\n",
    "The Tensorflor Estimator API requires a model function that returns an EstimatorSpec object describing what should be done when a training, evaluation, or prediction step is called. For serving, you only care about the prediction mode, so you can shortcut parts of the graph used for training and evaluation.\n",
    "\n",
    "TODO: Starting with resnet_model_fn() in https://github.com/tensorflow/models/blob/v1.4.0/official/resnet/imagenet_main.py, this function takes in a `features` argument that is a 4D tensor. Instead, we want to start with `features` that is a dictionary containing one key `'images'`, which stores a tensor of JPEG-encoded strings.\n",
    "\n",
    "TODO: Complete the exercises below to modify and simplify resnet_model_fn() appropriately. Notice that some of the shortcuts are already commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "\n",
    "def resnet_model_fn(features, labels, mode):\n",
    "  \"\"\"Our model_fn for ResNet to be used with our Estimator.\"\"\"\n",
    "  # TODO: Remove the summary as this is used during training/evaluation.\n",
    "  tf.summary.image('images', features, max_outputs=6)\n",
    "\n",
    "  # NOTE: New ops to convert tensor of jpegs to a 4d tensor.\n",
    "  images = features['images']  # A tensor of tf.strings\n",
    "  processed_images = tf.map_fn(preprocess_image, images, dtype=tf.float32)  # Convert to a list of tensors\n",
    "  processed_images = tf.stack(processed_images)  # Convert list of tensors to tensor of tensors\n",
    "  processed_images = tf.reshape(tensor=processed_images,  # Reshape to ensure TF graph knows the final dimensions\n",
    "                                shape=[-1, _DEFAULT_IMAGE_SIZE, _DEFAULT_IMAGE_SIZE, 3])\n",
    "\n",
    "  # TODO: Modify this line so this function works! The network must be IDENTICAL to the one used to train.\n",
    "  network = imagenet_resnet_v2(params['resnet_size'], params['data_format'])\n",
    "\n",
    "  # NOTE: is_training will be false since we are predicting.\n",
    "  logits = network(\n",
    "      inputs=processed_images, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "  # NOTE: Instead of the top 1 result, we can now return top k to the client!\n",
    "  top_k_logits, top_k_classes = tf.nn.top_k(logits, k=TOP_K)\n",
    "  top_k_probs = tf.nn.softmax(top_k_logits)\n",
    "  predictions = {\n",
    "      'classes': top_k_classes,\n",
    "      'probabilities': top_k_probs\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,  # This will not be used in serving, but must be provided anyway.\n",
    "        # TODO: To export the predictions dictionary above using Tf serving,\n",
    "        # you will need to assign the export_outputs parameter in EstimatorSpec.\n",
    "        # Add a dictionary with entry corresponding to the request.model_spec.signature_name that\n",
    "        # your client will call in `client/resnet_client.py`\n",
    "        export_outputs=  # TODO: Add entry here.\n",
    "    )\n",
    "\n",
    "  # TODO: Shortcut everything below here by returning a minimal EstimatorSpec.\n",
    "    \n",
    "  # Calculate loss, which includes softmax cross entropy and L2 regularization.\n",
    "  cross_entropy = tf.losses.softmax_cross_entropy(\n",
    "      logits=logits, onehot_labels=labels)\n",
    "\n",
    "  # Create a tensor named cross_entropy for logging purposes.\n",
    "  tf.identity(cross_entropy, name='cross_entropy')\n",
    "  tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "  # Add weight decay to the loss. We exclude the batch norm variables because\n",
    "  # doing so leads to a small improvement in accuracy.\n",
    "  loss = cross_entropy + _WEIGHT_DECAY * tf.add_n(\n",
    "      [tf.nn.l2_loss(v) for v in tf.trainable_variables()\n",
    "       if 'batch_normalization' not in v.name])\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    # Scale the learning rate linearly with the batch size. When the batch size\n",
    "    # is 256, the learning rate should be 0.1.\n",
    "    initial_learning_rate = 0.1 * params['batch_size'] / 256\n",
    "    batches_per_epoch = _NUM_IMAGES['train'] / params['batch_size']\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # Multiply the learning rate by 0.1 at 30, 60, 80, and 90 epochs.\n",
    "    boundaries = [\n",
    "        int(batches_per_epoch * epoch) for epoch in [30, 60, 80, 90]]\n",
    "    values = [\n",
    "        initial_learning_rate * decay for decay in [1, 0.1, 0.01, 1e-3, 1e-4]]\n",
    "    learning_rate = tf.train.piecewise_constant(\n",
    "        tf.cast(global_step, tf.int32), boundaries, values)\n",
    "\n",
    "    # Create a tensor named learning_rate for logging purposes.\n",
    "    tf.identity(learning_rate, name='learning_rate')\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(\n",
    "        learning_rate=learning_rate,\n",
    "        momentum=_MOMENTUM)\n",
    "\n",
    "    # Batch norm requires update_ops to be added as a train_op dependency.\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "      train_op = optimizer.minimize(loss, global_step)\n",
    "  else:\n",
    "    train_op = None\n",
    "\n",
    "  accuracy = tf.metrics.accuracy(\n",
    "      tf.argmax(labels, axis=1), predictions['classes'])\n",
    "  metrics = {'accuracy': accuracy}\n",
    "\n",
    "  # Create a tensor named train_accuracy for logging purposes.\n",
    "  tf.identity(accuracy[1], name='train_accuracy')\n",
    "  tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=predictions,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this model into our estimator\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=resnet_model_fn,  # Call our generate_model_fn to create model function\n",
    "  model_dir=MODEL_DIR,  # Where to look for model checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving input receiver function\n",
    "\n",
    "Tensorflow serving requires a serving input receiver function to be defined, which determines the format of the input from the client into the model function. The servable model will be expecting a protobuf from the client containing an 'images' field holding a list of JPEG-encoded strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "  return tf.estimator.export.build_raw_serving_input_receiver_fn(\n",
    "      {'images': tf.placeholder(dtype=tf.string, shape=[None])})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.export_savedmodel(export_dir_base=SERVING_DIR,\n",
    "                            serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
